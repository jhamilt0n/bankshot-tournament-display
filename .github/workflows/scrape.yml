name: Scrape Tournament Data

on:
  schedule:
    - cron: '*/60 * * * *'   # Every 60 minutes
    - cron: '0 12 * * *'     # 12:00 PM EDT (16:00 UTC)
    - cron: '30 12 * * *'    # 12:30 PM EDT (16:30 UTC)
    - cron: '0 12 * * *'     # 12:00 PM EDT (16:00 UTC)
    - cron: '30 12 * * *'    # 12:30 PM EDT (16:30 UTC)
    - cron: '30 23 * * *'    # 7:30 PM EDT (23:30 UTC)
    - cron: '45 23 * * *'    # 7:45 PM EDT (23:45 UTC)
    - cron: '30 0 * * *'     # 7:30 PM EST (00:30 UTC next day)
    - cron: '45 0 * * *'     # 7:45 PM EST (00:45 UTC next day)
  workflow_dispatch:         # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install Chrome and ChromeDriver
        run: |
          sudo apt-get update
          sudo apt-get install -y wget unzip chromium-browser chromium-chromedriver
          
      - name: Install Python dependencies
        run: |
          pip install selenium
      
      - name: Create necessary directories
        run: |
          mkdir -p logs
      
      - name: Run tournament scraper
        run: |
          echo "===================="
          echo "Starting scraper at $(date)"
          echo "===================="
          
          # Run scraper and capture exit code
          python3 scraper/bankshot_monitor_multi.py 2>&1 | tee scraper.log
          SCRAPER_EXIT_CODE=${PIPESTATUS[0]}
          
          echo "===================="
          echo "Scraper finished with exit code: $SCRAPER_EXIT_CODE"
          echo "===================="
          
          # Show what was written
          if [ -f tournament_data.json ]; then
            echo "tournament_data.json contents:"
            cat tournament_data.json
          else
            echo "ERROR: tournament_data.json was not created!"
          fi
          
          # Exit with scraper's exit code
          exit $SCRAPER_EXIT_CODE
        
      - name: Check for changes
        id: check_changes
        run: |
          git add tournament_data.json scraper.log 2>/dev/null || true
          
          if git diff --staged --quiet; then
            echo "changes=false" >> $GITHUB_OUTPUT
            echo "No changes detected in tournament_data.json"
          else
            echo "changes=true" >> $GITHUB_OUTPUT
            echo "Changes detected in tournament_data.json"
            git diff --staged tournament_data.json
          fi
      
      - name: Commit and push changes
        if: steps.check_changes.outputs.changes == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Bot"
          git commit -m "Update tournament data - $(date '+%Y-%m-%d %I:%M %p EST')"
          git push origin main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - name: No changes to commit
        if: steps.check_changes.outputs.changes == 'false'
        run: |
          echo "No changes detected - skipping commit"
          echo "This is normal if tournament data hasn't changed since last run"
          echo "Current tournament_data.json timestamp: $(jq -r '.last_updated' tournament_data.json || echo 'N/A')"
      
      - name: Upload scraper log as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-log-${{ github.run_number }}
          path: scraper.log
          retention-days: 7
